{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe0c6efc-4ab2-449e-92ed-03c9cf866afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from kagglex_cohort4 import *\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93251a0d-de87-4044-9b61-699a3f648343",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"train.csv\"\n",
    "raw = pd.read_csv(url, engine=\"pyarrow\", dtype_backend=\"pyarrow\")\n",
    "cars = clean_housing(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b75bf70-10f7-48ac-8d26-a6f98e7ba8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (54273, 12)\n",
      "y shape: (54273,)\n"
     ]
    }
   ],
   "source": [
    "target = \"price\"\n",
    "features = [col for col in cars.columns if col not in target]\n",
    "\n",
    "X = cars[features]\n",
    "y = cars[target]\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8990354-5625-4eae-bd47-c620bd007183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (40704, 12)\n",
      "y_train shape: (40704,)\n",
      "X_val shape: (13569, 12)\n",
      "y_val shape: (13569,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=43)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29c68901-70d7-4ea5-8e15-0eb0f8d76dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40704 entries, 11257 to 14148\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype          \n",
      "---  ------        --------------  -----          \n",
      " 0   id            40704 non-null  uint16[pyarrow]\n",
      " 1   brand         40704 non-null  category       \n",
      " 2   model         40704 non-null  category       \n",
      " 3   model_year    40704 non-null  uint16[pyarrow]\n",
      " 4   milage        40704 non-null  uint32[pyarrow]\n",
      " 5   fuel_type     40704 non-null  category       \n",
      " 6   engine        40704 non-null  category       \n",
      " 7   transmission  40704 non-null  category       \n",
      " 8   ext_col       40704 non-null  category       \n",
      " 9   int_col       40704 non-null  category       \n",
      " 10  accident      40704 non-null  category       \n",
      " 11  clean_title   40704 non-null  category       \n",
      "dtypes: category(9), uint16[pyarrow](2), uint32[pyarrow](1)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "816808d8-7972-4646-a91c-6b374dac50df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numerical columns\n",
    "cat = list(X.select_dtypes(include=['category']).columns)\n",
    "num = list(X.select_dtypes(include=['number']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fab8bf45-38d4-4197-b992-05031f50dc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat),\n",
    "        ('num', StandardScaler(), num)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9f6cbf5-c5fd-4646-b824-1c55d47e610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline with XGBRegressor\n",
    "xgb_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor(objective='reg:squarederror', random_state=43, tree_method='gpu_hist', predictor='gpu_predictor'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6dac4d14-20fd-4259-b2ee-63aafb438a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the Hyperparameter Universe\n",
    "param_grid = {\n",
    "    'regressor__learning_rate': [0.01, 0.1, 0.2],  # Controls the step size at each iteration\n",
    "    'regressor__n_estimators': [100, 200, 300],  # Number of boosting rounds\n",
    "    'regressor__max_depth': [3, 5, 7],  # Maximum depth of a tree\n",
    "    'regressor__min_child_weight': [1, 3, 5],  # Minimum sum of instance weight in a child\n",
    "    'regressor__subsample': [0.6, 0.8, 1.0],  # Fraction of training data sampled for each tree\n",
    "    'regressor__colsample_bytree': [0.6, 0.8, 1.0],  # Fraction of features sampled for each tree\n",
    "    'regressor__gamma': [0, 0.1, 0.2],  # Minimum loss reduction for a further partition\n",
    "    'regressor__reg_lambda': [1, 1.5, 2],  # L2 regularization term on weights\n",
    "    'regressor__reg_alpha': [0, 0.1, 0.5]  # L1 regularization term on weights\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "897383d2-b33c-4238-9f0e-1cfd0ed600d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Choose the Search Strategy\n",
    "def hyperparameter_search(X_train, y_train, search_strategy='grid', n_iter=10):\n",
    "    if search_strategy == 'grid':\n",
    "        search = GridSearchCV(estimator=xgb_pipe, param_grid=param_grid, scoring='neg_root_mean_squared_error', cv=3, verbose=1, n_jobs=-1)\n",
    "    elif search_strategy == 'random':\n",
    "        search = RandomizedSearchCV(estimator=xgb_pipe, param_distributions=param_grid, n_iter=n_iter, scoring='neg_root_mean_squared_error', cv=3, verbose=1, random_state=42, n_jobs=-1)\n",
    "    else:\n",
    "        raise ValueError(\"search_strategy must be either 'grid' or 'random'\")\n",
    "    \n",
    "    # Step 3: Execute the Search\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    # Step 4: Evaluate and Iterate\n",
    "    print(f\"Best parameters found: {search.best_params_}\")\n",
    "    print(f\"Best score (negative RMSE): {-search.best_score_}\")\n",
    "    \n",
    "    return search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d39c65-314b-4bd9-b07c-fad45bbc04c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 19683 candidates, totalling 59049 fits\n"
     ]
    }
   ],
   "source": [
    "# Perform hyperparameter search using GridSearchCV\n",
    "best_model_grid = hyperparameter_search(X_train, y_train, search_strategy='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cadda19-c457-40f7-af87-2c98947396ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform hyperparameter search using RandomizedSearchCV\n",
    "best_model_random = hyperparameter_search(X_train, y_train, search_strategy='random', n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c30665-6e40-47e8-87fe-eabee4ddc063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best models found\n",
    "y_pred_grid = best_model_grid.predict(X_val)\n",
    "y_pred_random = best_model_random.predict(X_val)\n",
    "\n",
    "rmse_grid = np.sqrt(mean_squared_error(y_val, y_pred_grid))\n",
    "rmse_random = np.sqrt(mean_squared_error(y_val, y_pred_random))\n",
    "\n",
    "print(f\"Test RMSE (GridSearchCV): {rmse_grid}\")\n",
    "print(f\"Test RMSE (RandomizedSearchCV): {rmse_random}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dabb3c-c702-474a-9898-a8bff521dd8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c848606b-859b-4054-aff1-212a6ae78305",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.read_csv(\"test.csv\")  # REMOVERHS\n",
    "print(X_test.info())\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0e9ae2-81c7-4c49-84b5-3b0ee12e1b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = pd.Series(xgb_pipe.predict(X_test))  # REMOVERHS\n",
    "y_test_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381012ce-4420-4bc9-aa41-b822c551b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_imp = (pd\n",
    "            .Series(xgb_model.feature_importances_, index=feature_names)\n",
    "            .sort_values(key=abs, ascending=False)\n",
    "           ) \n",
    "feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d45af6e-b3bd-4cac-8fc5-bb6f8cbe7b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the submission file\n",
    "submission_example = pd.read_csv('sample_submission.csv')\n",
    "submission = pd.DataFrame({'id': submission_example['id'], 'target': y_test_pred})\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "86c0d6eb-dab6-49fe-beee-94e7a7088813",
   "metadata": {},
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming the necessary libraries and functions (like clean_housing) are already imported and defined\n",
    "\n",
    "# Load and clean the dataset\n",
    "url = \"train.csv\"\n",
    "raw = pd.read_csv(url, engine=\"pyarrow\", dtype_backend=\"pyarrow\")\n",
    "cars = clean_housing(raw)\n",
    "\n",
    "# Define the target and features\n",
    "target = \"price\"\n",
    "features = [col for col in cars.columns if col != target]\n",
    "\n",
    "X = cars[features]\n",
    "y = cars[target]\n",
    "\n",
    "# Split the dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=43)\n",
    "\n",
    "# Identify categorical and numerical columns\n",
    "cat = list(X.select_dtypes(include=['category']).columns)\n",
    "num = list(X.select_dtypes(include=['number']).columns)\n",
    "\n",
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat),\n",
    "        ('num', StandardScaler(), num)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Define the pipeline with XGBRegressor\n",
    "xgb_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', xgb.XGBRegressor(objective='reg:squarederror', random_state=43, tree_method='gpu_hist', predictor='gpu_predictor', early_stopping_rounds=10))\n",
    "])\n",
    "\n",
    "# Step 1: Define the Hyperparameter Universe\n",
    "# Reduced hyperparameter grid for faster search\n",
    "param_grid = {\n",
    "    'regressor__learning_rate': [0.01, 0.1],  # Controls the step size at each iteration\n",
    "    'regressor__n_estimators': [100, 200],  # Number of boosting rounds\n",
    "    'regressor__max_depth': [3, 5],  # Maximum depth of a tree\n",
    "    'regressor__min_child_weight': [1, 3],  # Minimum sum of instance weight in a child\n",
    "    'regressor__subsample': [0.8, 1.0],  # Fraction of training data sampled for each tree\n",
    "    'regressor__colsample_bytree': [0.8, 1.0],  # Fraction of features sampled for each tree\n",
    "    'regressor__gamma': [0, 0.1],  # Minimum loss reduction for a further partition\n",
    "    'regressor__reg_lambda': [1, 1.5],  # L2 regularization term on weights\n",
    "    'regressor__reg_alpha': [0, 0.1]  # L1 regularization term on weights\n",
    "}\n",
    "\n",
    "# Step 2: Choose the Search Strategy\n",
    "def hyperparameter_search(X_train, y_train, X_val, y_val, search_strategy='grid', n_iter=10):\n",
    "    if search_strategy == 'grid':\n",
    "        search = GridSearchCV(estimator=xgb_pipe, param_grid=param_grid, scoring='neg_root_mean_squared_error', cv=3, verbose=1, n_jobs=-1)\n",
    "    elif search_strategy == 'random':\n",
    "        search = RandomizedSearchCV(estimator=xgb_pipe, param_distributions=param_grid, n_iter=n_iter, scoring='neg_root_mean_squared_error', cv=3, verbose=1, random_state=42, n_jobs=-1)\n",
    "    else:\n",
    "        raise ValueError(\"search_strategy must be either 'grid' or 'random'\")\n",
    "    \n",
    "    # Step 3: Execute the Search with early stopping\n",
    "    search.fit(X_train, y_train, regressor__eval_set=[(X_val, y_val)], regressor__early_stopping_rounds=10, regressor__verbose=False)\n",
    "    \n",
    "    # Step 4: Evaluate and Iterate\n",
    "    print(f\"Best parameters found: {search.best_params_}\")\n",
    "    print(f\"Best score (negative RMSE): {-search.best_score_}\")\n",
    "    \n",
    "    return search.best_estimator_\n",
    "\n",
    "# Perform hyperparameter search using RandomizedSearchCV\n",
    "best_model_random = hyperparameter_search(X_train, y_train, X_val, y_val, search_strategy='random', n_iter=50)\n",
    "\n",
    "# Evaluate the best model found\n",
    "y_pred_random = best_model_random.predict(X_val)\n",
    "\n",
    "rmse_random = np.sqrt(mean_squared_error(y_val, y_pred_random))\n",
    "\n",
    "print(f\"Test RMSE (RandomizedSearchCV): {rmse_random}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
