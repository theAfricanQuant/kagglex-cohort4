{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe0c6efc-4ab2-449e-92ed-03c9cf866afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from category_encoders import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from kagglex_cohort4 import *\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93251a0d-de87-4044-9b61-699a3f648343",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"train.csv\"\n",
    "raw = pd.read_csv(url, engine=\"pyarrow\", dtype_backend=\"pyarrow\")\n",
    "cars = clean_housing(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1b75bf70-10f7-48ac-8d26-a6f98e7ba8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (54273, 12)\n",
      "y shape: (54273,)\n"
     ]
    }
   ],
   "source": [
    "target = \"price\"\n",
    "features = [col for col in cars.columns if col not in target]\n",
    "\n",
    "X = cars[features]\n",
    "y = cars[target]\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8990354-5625-4eae-bd47-c620bd007183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (40704, 12)\n",
      "y_train shape: (40704,)\n",
      "X_val shape: (13569, 12)\n",
      "y_val shape: (13569,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=43)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)\n",
    "print(\"X_val shape:\", X_val.shape)\n",
    "print(\"y_val shape:\", y_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29c68901-70d7-4ea5-8e15-0eb0f8d76dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 40704 entries, 11257 to 14148\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype          \n",
      "---  ------        --------------  -----          \n",
      " 0   id            40704 non-null  uint16[pyarrow]\n",
      " 1   brand         40704 non-null  category       \n",
      " 2   model         40704 non-null  category       \n",
      " 3   model_year    40704 non-null  uint16[pyarrow]\n",
      " 4   milage        40704 non-null  uint32[pyarrow]\n",
      " 5   fuel_type     40704 non-null  category       \n",
      " 6   engine        40704 non-null  category       \n",
      " 7   transmission  40704 non-null  category       \n",
      " 8   ext_col       40704 non-null  category       \n",
      " 9   int_col       40704 non-null  category       \n",
      " 10  accident      40704 non-null  category       \n",
      " 11  clean_title   40704 non-null  category       \n",
      "dtypes: category(9), uint16[pyarrow](2), uint32[pyarrow](1)\n",
      "memory usage: 1.3 MB\n"
     ]
    }
   ],
   "source": [
    "X_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "816808d8-7972-4646-a91c-6b374dac50df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify categorical and numerical columns\n",
    "cat = list(X.select_dtypes(include=['category']).columns)\n",
    "num = list(X.select_dtypes(include=['number']).columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fab8bf45-38d4-4197-b992-05031f50dc7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the column transformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat),\n",
    "        ('num', StandardScaler(), num)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9f6cbf5-c5fd-4646-b824-1c55d47e610f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline with XGBRegressor\n",
    "xgb_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', XGBRegressor(objective='reg:squarederror', random_state=43, tree_method='gpu_hist', predictor='gpu_predictor'))\n",
    "])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a1b54baa-764e-4226-93c2-b88df2e24d70",
   "metadata": {},
   "source": [
    "# Step 1: Define the Hyperparameter Universe\n",
    "param_grid = {\n",
    "    'regressor__learning_rate': [0.01, 0.1, 0.2],  # Controls the step size at each iteration\n",
    "    'regressor__n_estimators': [100, 200, 300],  # Number of boosting rounds\n",
    "    'regressor__max_depth': [3, 5, 7],  # Maximum depth of a tree\n",
    "    'regressor__min_child_weight': [1, 3, 5],  # Minimum sum of instance weight in a child\n",
    "    'regressor__subsample': [0.6, 0.8, 1.0],  # Fraction of training data sampled for each tree\n",
    "    'regressor__colsample_bytree': [0.6, 0.8, 1.0],  # Fraction of features sampled for each tree\n",
    "    'regressor__gamma': [0, 0.1, 0.2],  # Minimum loss reduction for a further partition\n",
    "    'regressor__reg_lambda': [1, 1.5, 2],  # L2 regularization term on weights\n",
    "    'regressor__reg_alpha': [0, 0.1, 0.5]  # L1 regularization term on weights\n",
    "}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "339a3757-9f6b-498b-b1fb-e96f436dc26f",
   "metadata": {},
   "source": [
    "# Step 2: Choose the Search Strategy\n",
    "def hyperparameter_search(X_train, y_train, search_strategy='grid', estimator=xgb_pipe, param_grid=param_grid, n_iter=10):\n",
    "    if search_strategy == 'grid':\n",
    "        search = GridSearchCV(estimator=xgb_pipe, param_grid=param_grid, scoring='neg_root_mean_squared_error', cv=3, verbose=1, n_jobs=-1)\n",
    "    elif search_strategy == 'random':\n",
    "        search = RandomizedSearchCV(estimator=xgb_pipe, param_distributions=param_grid, n_iter=n_iter, scoring='neg_root_mean_squared_error', cv=3, verbose=1, random_state=42, n_jobs=-1)\n",
    "    else:\n",
    "        raise ValueError(\"search_strategy must be either 'grid' or 'random'\")\n",
    "    \n",
    "    # Step 3: Execute the Search\n",
    "    search.fit(X_train, y_train)\n",
    "    \n",
    "    # Step 4: Evaluate and Iterate\n",
    "    print(f\"Best parameters found: {search.best_params_}\")\n",
    "    print(f\"Best score (negative RMSE): {-search.best_score_}\")\n",
    "    \n",
    "    return search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4e45ec2e-4222-4da3-98e1-af2038a5b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define the Hyperparameter Universe\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [2, 25, 50, 75, 100, 200, 300],  # Number of boosting rounds\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "14d39c65-314b-4bd9-b07c-fad45bbc04c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 7 candidates, totalling 21 fits\n",
      "Best parameters found: {'regressor__n_estimators': 2}\n",
      "Best score (negative RMSE): 80691.0645083222\n"
     ]
    }
   ],
   "source": [
    "# Perform hyperparameter search using GridSearchCV\n",
    "best_model_grid = hyperparameter_search(X_train=X_train, y_train=y_train, estimator=xgb_pipe, param_grid=param_grid, search_strategy='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa991aec-f17e-4e24-a291-151e2f442305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n",
      "Best parameters found: {'regressor__max_depth': 1, 'regressor__n_estimators': 2}\n",
      "Best score (negative RMSE): 76789.43671946565\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define the Hyperparameter Universe\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [2],  # Number of boosting rounds\n",
    "    'regressor__max_depth': [1, 3, 5, 7],  # Maximum depth of a tree\n",
    "}\n",
    "\n",
    "best_model_grid = hyperparameter_search(X_train=X_train, y_train=y_train, estimator=xgb_pipe, param_grid=param_grid, search_strategy='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2c8bddee-ee4c-4d52-8a69-259b7f76ddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n",
      "Best parameters found: {'regressor__learning_rate': 0.5, 'regressor__max_depth': 1, 'regressor__n_estimators': 2}\n",
      "Best score (negative RMSE): 74483.83900231989\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Define the Hyperparameter Universe\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [2],  # Number of boosting rounds\n",
    "    'regressor__max_depth': [1],  # Maximum depth of a tree\n",
    "    'regressor__learning_rate': [0.01, 0.1, 0.2, 0.3, 0.4, 0.5],  # Controls the step size at each iteration\n",
    "}\n",
    "best_model_grid = hyperparameter_search(X_train=X_train, y_train=y_train, estimator=xgb_pipe, param_grid=param_grid, search_strategy='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bbf43993-76f6-42b1-a38b-50daf0e99115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n",
      "Best parameters found: {'regressor__learning_rate': 0.5, 'regressor__max_depth': 1, 'regressor__min_child_weight': 1, 'regressor__n_estimators': 2}\n",
      "Best score (negative RMSE): 74483.83900231989\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'regressor__n_estimators': [2],  # Number of boosting rounds\n",
    "    'regressor__max_depth': [1],  # Maximum depth of a tree\n",
    "    'regressor__learning_rate': [0.5],  # Controls the step size at each iteration\n",
    "    'regressor__min_child_weight': [1, 2, 3, 4, 5],  # Minimum sum of instance weight in a child\n",
    "}\n",
    "\n",
    "best_model_grid = hyperparameter_search(X_train=X_train, y_train=y_train, estimator=xgb_pipe, param_grid=param_grid, search_strategy='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b17e53cd-1021-4a2a-8d20-3e916111eb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "Best parameters found: {'regressor__learning_rate': 0.5, 'regressor__max_depth': 1, 'regressor__min_child_weight': 1, 'regressor__n_estimators': 2, 'regressor__subsample': 1.0}\n",
      "Best score (negative RMSE): 74483.83900231989\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'regressor__n_estimators': [2],  # Number of boosting rounds\n",
    "    'regressor__max_depth': [1],  # Maximum depth of a tree\n",
    "    'regressor__learning_rate': [0.5],  # Controls the step size at each iteration\n",
    "    'regressor__min_child_weight': [1],  # Minimum sum of instance weight in a child\n",
    "    'regressor__subsample': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0],  # Fraction of training data sampled for each tree\n",
    "}\n",
    "\n",
    "best_model_grid = hyperparameter_search(X_train=X_train, y_train=y_train, estimator=xgb_pipe, param_grid=param_grid, search_strategy='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51b6e849-f5b5-41a6-a804-2178fe41567a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best parameters found: {'regressor__colsample_bytree': 0.8, 'regressor__learning_rate': 0.5, 'regressor__max_depth': 1, 'regressor__min_child_weight': 1, 'regressor__n_estimators': 2, 'regressor__subsample': 1.0}\n",
      "Best score (negative RMSE): 74483.83900231989\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'regressor__n_estimators': [2],  # Number of boosting rounds\n",
    "    'regressor__max_depth': [1],  # Maximum depth of a tree\n",
    "    'regressor__learning_rate': [0.5],  # Controls the step size at each iteration\n",
    "    'regressor__min_child_weight': [1],  # Minimum sum of instance weight in a child\n",
    "    'regressor__subsample': [1.0],  # Fraction of training data sampled for each tree\n",
    "    'regressor__colsample_bytree': [0.6, 0.8, 1.0],  # Fraction of features sampled for each tree\n",
    "}\n",
    "\n",
    "best_model_grid = hyperparameter_search(X_train=X_train, y_train=y_train, estimator=xgb_pipe, param_grid=param_grid, search_strategy='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd8c18e3-ed10-40f5-9c62-81ae459bcaea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 108 candidates, totalling 324 fits\n",
      "Best parameters found: {'regressor__colsample_bylevel': 0.8, 'regressor__colsample_bynode': 0.8, 'regressor__colsample_bytree': 1.0, 'regressor__learning_rate': 0.5, 'regressor__max_depth': 1, 'regressor__min_child_weight': 1, 'regressor__n_estimators': 2, 'regressor__subsample': 1.0}\n",
      "Best score (negative RMSE): 74471.13020770096\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'regressor__n_estimators': [2],  # Number of boosting rounds\n",
    "    'regressor__max_depth': [1],  # Maximum depth of a tree\n",
    "    'regressor__learning_rate': [0.5],  # Controls the step size at each iteration\n",
    "    'regressor__min_child_weight': [1],  # Minimum sum of instance weight in a child\n",
    "    'regressor__subsample': [1.0],  # Fraction of training data sampled for each tree\n",
    "    'regressor__colsample_bytree': [0.6, 0.8, 1.0],  # Fraction of features sampled for each tree\n",
    "    'regressor__colsample_bylevel':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "    'regressor__colsample_bynode':[0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "}\n",
    "\n",
    "best_model_grid = hyperparameter_search(X_train=X_train, y_train=y_train, estimator=xgb_pipe, param_grid=param_grid, search_strategy='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f4f3f61-6f05-4d8a-9d55-811746b5fa5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best parameters found: {'regressor__colsample_bylevel': 0.8, 'regressor__colsample_bynode': 0.8, 'regressor__colsample_bytree': 1.0, 'regressor__gamma': 0, 'regressor__learning_rate': 0.5, 'regressor__max_depth': 1, 'regressor__min_child_weight': 1, 'regressor__n_estimators': 2, 'regressor__subsample': 1.0}\n",
      "Best score (negative RMSE): 74471.13020770096\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'regressor__n_estimators': [2],  # Number of boosting rounds\n",
    "    'regressor__max_depth': [1],  # Maximum depth of a tree\n",
    "    'regressor__learning_rate': [0.5],  # Controls the step size at each iteration\n",
    "    'regressor__min_child_weight': [1],  # Minimum sum of instance weight in a child\n",
    "    'regressor__subsample': [1.0],  # Fraction of training data sampled for each tree\n",
    "    'regressor__colsample_bytree': [1.0],  # Fraction of features sampled for each tree\n",
    "    'regressor__colsample_bylevel':[0.8],\n",
    "    'regressor__colsample_bynode':[0.8],\n",
    "    'regressor__gamma': [0, 0.1, 0.2],  # Minimum loss reduction for a further partition\n",
    "}\n",
    "\n",
    "best_model_grid = hyperparameter_search(X_train=X_train, y_train=y_train, estimator=xgb_pipe, param_grid=param_grid, search_strategy='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5daae102-3097-41a3-b240-e3a5a4b6f080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "Best parameters found: {'regressor__colsample_bylevel': 0.8, 'regressor__colsample_bynode': 0.8, 'regressor__colsample_bytree': 1.0, 'regressor__gamma': 0, 'regressor__learning_rate': 0.5, 'regressor__max_depth': 1, 'regressor__min_child_weight': 1, 'regressor__n_estimators': 2, 'regressor__reg_lambda': 1, 'regressor__subsample': 1.0}\n",
      "Best score (negative RMSE): 74471.13020770096\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'regressor__n_estimators': [2],  # Number of boosting rounds\n",
    "    'regressor__max_depth': [1],  # Maximum depth of a tree\n",
    "    'regressor__learning_rate': [0.5],  # Controls the step size at each iteration\n",
    "    'regressor__min_child_weight': [1],  # Minimum sum of instance weight in a child\n",
    "    'regressor__subsample': [1.0],  # Fraction of training data sampled for each tree\n",
    "    'regressor__colsample_bytree': [1.0],  # Fraction of features sampled for each tree\n",
    "    'regressor__colsample_bylevel':[0.8],\n",
    "    'regressor__colsample_bynode':[0.8],\n",
    "    'regressor__gamma': [0],  # Minimum loss reduction for a further partition\n",
    "    'regressor__reg_lambda': [1, 1.5, 2],  # L2 regularization term on weights\n",
    "}\n",
    "\n",
    "best_model_grid = hyperparameter_search(X_train=X_train, y_train=y_train, estimator=xgb_pipe, param_grid=param_grid, search_strategy='grid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a573a3cf-67d4-49ed-a549-e22e503661fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Best parameters found: {'regressor__colsample_bylevel': 0.8, 'regressor__colsample_bynode': 0.8, 'regressor__colsample_bytree': 1.0, 'regressor__gamma': 0, 'regressor__learning_rate': 0.5, 'regressor__max_depth': 1, 'regressor__min_child_weight': 1, 'regressor__n_estimators': 2, 'regressor__reg_alpha': 0, 'regressor__reg_lambda': 1, 'regressor__subsample': 1.0}\n",
      "Best score (negative RMSE): 74471.13020770096\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'regressor__n_estimators': [2],  # Number of boosting rounds (Default: 100)\n",
    "    'regressor__max_depth': [1],  # Maximum depth of a tree (Default: 6)\n",
    "    'regressor__learning_rate': [0.5],  # Controls the step size at each iteration (Default: 0.3)\n",
    "    'regressor__min_child_weight': [1],  # Minimum sum of instance weight (hessian) in a child (Default: 1)\n",
    "    'regressor__subsample': [1.0],  # Fraction of training data sampled for each tree (Default: 1.0)\n",
    "    'regressor__colsample_bytree': [1.0],  # Fraction of features sampled for each tree (Default: 1.0)\n",
    "    'regressor__colsample_bylevel': [0.8],  # Fraction of features sampled for each level (Default: 1.0)\n",
    "    'regressor__colsample_bynode': [0.8],  # Fraction of features sampled for each node (Default: 1.0)\n",
    "    'regressor__gamma': [0],  # Minimum loss reduction required to make a further partition on a leaf node (Default: 0)\n",
    "    'regressor__reg_lambda': [1],  # L2 regularization term on weights (Default: 1)\n",
    "    'regressor__reg_alpha': [0]  # L1 regularization term on weights (Default: 0)\n",
    "}\n",
    "\n",
    "best_model_grid = hyperparameter_search(X_train=X_train, y_train=y_train, estimator=xgb_pipe, param_grid=param_grid, search_strategy='grid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "481e817e-4b0d-444a-b471-437cfee6e450",
   "metadata": {},
   "source": [
    "Here are your chosen parameters with comments describing what they do and their default values:\n",
    "\n",
    "```python\n",
    "param_grid = {\n",
    "    'regressor__n_estimators': [2],  # Number of boosting rounds (Default: 100)\n",
    "    'regressor__max_depth': [1],  # Maximum depth of a tree (Default: 6)\n",
    "    'regressor__learning_rate': [0.5],  # Controls the step size at each iteration (Default: 0.3)\n",
    "    'regressor__min_child_weight': [1],  # Minimum sum of instance weight (hessian) in a child (Default: 1)\n",
    "    'regressor__subsample': [1.0],  # Fraction of training data sampled for each tree (Default: 1.0)\n",
    "    'regressor__colsample_bytree': [1.0],  # Fraction of features sampled for each tree (Default: 1.0)\n",
    "    'regressor__colsample_bylevel': [0.8],  # Fraction of features sampled for each level (Default: 1.0)\n",
    "    'regressor__colsample_bynode': [0.8],  # Fraction of features sampled for each node (Default: 1.0)\n",
    "    'regressor__gamma': [0],  # Minimum loss reduction required to make a further partition on a leaf node (Default: 0)\n",
    "    'regressor__reg_lambda': [1],  # L2 regularization term on weights (Default: 1)\n",
    "    'regressor__reg_alpha': [0]  # L1 regularization term on weights (Default: 0)\n",
    "}\n",
    "```\n",
    "\n",
    "Here's a breakdown of each parameter with its default value and description:\n",
    "\n",
    "- **`n_estimators`**: Specifies the number of boosting rounds. Default value is 100.\n",
    "- **`max_depth`**: Determines the maximum depth of the trees. Default value is 6.\n",
    "- **`learning_rate`**: Also known as eta, it controls the step size at each iteration. Default value is 0.3.\n",
    "- **`min_child_weight`**: Minimum sum of instance weight (hessian) needed in a child. Default value is 1.\n",
    "- **`subsample`**: Fraction of the training data to be randomly sampled for each tree. Default value is 1.0.\n",
    "- **`colsample_bytree`**: Fraction of features to be randomly sampled for each tree. Default value is 1.0.\n",
    "- **`colsample_bylevel`**: Fraction of features to be randomly sampled for each level. Default value is 1.0.\n",
    "- **`colsample_bynode`**: Fraction of features to be randomly sampled for each node. Default value is 1.0.\n",
    "- **`gamma`**: Minimum loss reduction required to make a further partition on a leaf node. Default value is 0.\n",
    "- **`reg_lambda`**: L2 regularization term on weights (ridge regression). Default value is 1.\n",
    "- **`reg_alpha`**: L1 regularization term on weights (Lasso regression). Default value is 0."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6776b7-894a-40e6-bbb3-07ba797395b5",
   "metadata": {},
   "source": [
    "## RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3cbc4e45-e650-4ac4-a916-8874ae83b553",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n",
      "Best parameters found: {'regressor__subsample': 0.8, 'regressor__reg_lambda': 0.1, 'regressor__reg_alpha': 1, 'regressor__n_estimators': 500, 'regressor__min_child_weight': 9, 'regressor__max_depth': 6, 'regressor__learning_rate': 0.05, 'regressor__gamma': 0.1, 'regressor__colsample_bytree': 0.7, 'regressor__colsample_bynode': 0.7, 'regressor__colsample_bylevel': 0.8}\n",
      "Best score (negative RMSE): 76143.56330864866\n"
     ]
    }
   ],
   "source": [
    "param_grid = {\n",
    "    'regressor__n_estimators': [int(x) for x in range(50, 501, 50)],  # Number of boosting rounds (Default: 100)\n",
    "    'regressor__max_depth': [int(x) for x in range(1, 11)],  # Maximum depth of a tree (Default: 6)\n",
    "    'regressor__learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3, 0.4, 0.5],  # Controls the step size at each iteration (Default: 0.3)\n",
    "    'regressor__min_child_weight': [int(x) for x in range(1, 11)],  # Minimum sum of instance weight (hessian) in a child (Default: 1)\n",
    "    'regressor__subsample': [0.6, 0.7, 0.8, 0.9, 1.0],  # Fraction of training data sampled for each tree (Default: 1.0)\n",
    "    'regressor__colsample_bytree': [0.6, 0.7, 0.8, 0.9, 1.0],  # Fraction of features sampled for each tree (Default: 1.0)\n",
    "    'regressor__colsample_bylevel': [0.6, 0.7, 0.8, 0.9, 1.0],  # Fraction of features sampled for each level (Default: 1.0)\n",
    "    'regressor__colsample_bynode': [0.6, 0.7, 0.8, 0.9, 1.0],  # Fraction of features sampled for each node (Default: 1.0)\n",
    "    'regressor__gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5],  # Minimum loss reduction required to make a further partition on a leaf node (Default: 0)\n",
    "    'regressor__reg_lambda': [0.1, 0.5, 1, 1.5, 2],  # L2 regularization term on weights (Default: 1)\n",
    "    'regressor__reg_alpha': [0, 0.1, 0.5, 1, 1.5, 2]  # L1 regularization term on weights (Default: 0)\n",
    "}\n",
    "best_model_grid = hyperparameter_search(X_train=X_train, y_train=y_train, estimator=xgb_pipe, param_grid=param_grid, search_strategy='random', n_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cadda19-c457-40f7-af87-2c98947396ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "rscv_params = {\n",
    "    'regressor__n_estimators': 500,  # Number of boosting rounds\n",
    "    'regressor__max_depth': 6,  # Maximum depth of a tree\n",
    "    'regressor__learning_rate': 0.05,  # Controls the step size at each iteration\n",
    "    'regressor__min_child_weight': 9,  # Minimum sum of instance weight in a child\n",
    "    'regressor__subsample': 0.8,  # Fraction of training data sampled for each tree\n",
    "    'regressor__colsample_bytree': 0.7,  # Fraction of features sampled for each tree\n",
    "    'regressor__colsample_bylevel': 0.8,  # Fraction of features sampled for each level\n",
    "    'regressor__colsample_bynode': 0.7,  # Fraction of features sampled for each node\n",
    "    'regressor__gamma': 0.1,  # Minimum loss reduction required to make a further partition on a leaf node\n",
    "    'regressor__reg_lambda': 0.1,  # L2 regularization term on weights\n",
    "    'regressor__reg_alpha': 1  # L1 regularization term on weights\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27d5f7c2-b007-4e51-88ea-4fb998b2d272",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'n_estimators': 200, \n",
    "    'max_depth': 3, \n",
    "    'learning_rate': 0.01, \n",
    "    'min_child_weight': 9, \n",
    "    'subsample': 0.8, \n",
    "    'colsample_bytree': 0.9, \n",
    "    'colsample_bylevel': 0.9, \n",
    "    'colsample_bynode': 0.7, \n",
    "    'gamma': 0.4, \n",
    "    'reg_lambda': 2, \n",
    "    'reg_alpha': 2\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
